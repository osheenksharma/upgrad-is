{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b040ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7940c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset into a Pandas DataFrame\n",
    "\n",
    "df = pd.read_csv('Dataset_Uber Traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddcb5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DateTime  Junction  Vehicles           ID\n",
      "0  01/11/15 0:00         1        15  20151101001\n",
      "1  01/11/15 1:00         1        13  20151101011\n",
      "2  01/11/15 2:00         1        10  20151101021\n",
      "3  01/11/15 3:00         1         7  20151101031\n",
      "4  01/11/15 4:00         1         9  20151101041\n"
     ]
    }
   ],
   "source": [
    "#Display the first few rows of the dataset\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ecab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Junction      Vehicles            ID\n",
      "count  48120.000000  48120.000000  4.812000e+04\n",
      "mean       2.180549     22.791334  2.016330e+10\n",
      "std        0.966955     20.750063  5.944854e+06\n",
      "min        1.000000      1.000000  2.015110e+10\n",
      "25%        1.000000      9.000000  2.016042e+10\n",
      "50%        2.000000     15.000000  2.016093e+10\n",
      "75%        3.000000     29.000000  2.017023e+10\n",
      "max        4.000000    180.000000  2.017063e+10\n"
     ]
    }
   ],
   "source": [
    "#Summary statistics\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a91f7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48120 entries, 0 to 48119\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   DateTime  48120 non-null  object\n",
      " 1   Junction  48120 non-null  int64 \n",
      " 2   Vehicles  48120 non-null  int64 \n",
      " 3   ID        48120 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Information about the dataset\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba8d71f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateTime    0\n",
      "Junction    0\n",
      "Vehicles    0\n",
      "ID          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check for missing values\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "044d422b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Since there are no missing values, we proceed with cleaning the dataset.\n",
    "#Identify duplicates\n",
    "\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c495d916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime    object\n",
       "Junction     int64\n",
       "Vehicles     int64\n",
       "ID           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since there are no duplicate values, we proceed with correcting the datatypes.\n",
    "#Identify datatypes\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "874bb6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To aggregate traffic data-\n",
    "#Step 1: Parse DateTime column\n",
    "\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02d3e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Set DateTime as index\n",
    "\n",
    "df.set_index('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dae43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Group by Junction and resample the data to hourly intervals, aggregating the relevant data \n",
    "#(vehicle counts, speeds, and congestion levels)\n",
    "\n",
    "hourly_traffic = df.groupby('Junction').resample('H').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "756dc88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Junction  Vehicles            ID\n",
      "0           1.0      15.0  2.015110e+10\n",
      "1           1.0      13.0  2.015110e+10\n",
      "2           1.0      10.0  2.015110e+10\n",
      "3           1.0       7.0  2.015110e+10\n",
      "4           1.0       9.0  2.015110e+10\n",
      "...         ...       ...           ...\n",
      "84547       4.0      10.0  2.017061e+10\n",
      "84548       4.0       7.0  2.017061e+10\n",
      "84549       4.0       8.0  2.017061e+10\n",
      "84550       4.0      11.0  2.017061e+10\n",
      "84551       4.0      11.0  2.017061e+10\n",
      "\n",
      "[84552 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Reset the index to have a clean DataFrame\n",
    "\n",
    "hourly_traffic = hourly_traffic.reset_index(drop=True)\n",
    "\n",
    "print(hourly_traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d11b0fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Junction  Vehicles            ID\n",
      "0       0.0  0.078212  0.000000e+00\n",
      "1       0.0  0.067039  5.120530e-07\n",
      "2       0.0  0.050279  1.024106e-06\n",
      "3       0.0  0.033520  1.536159e-06\n",
      "4       0.0  0.044693  2.048212e-06\n"
     ]
    }
   ],
   "source": [
    "#Extract the numerical columns to be normalized or standardized\n",
    "\n",
    "numerical_columns = ['Junction', 'Vehicles', 'ID']\n",
    "\n",
    "#Normalize the data\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(df[numerical_columns])\n",
    "df_normalized = pd.DataFrame(normalized_data, columns=numerical_columns)\n",
    "print(df_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff5c0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new features from raw data\n",
    "#Step 1: Time-Based Features\n",
    "\n",
    "df['DateTime'] = df.index\n",
    "\n",
    "#Now, let's proceed with extracting time-based features\n",
    "df['Hour'] = df['DateTime'].dt.hour\n",
    "df['DayOfWeek'] = df['DateTime'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['Month'] = df['DateTime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d143e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Lag Features (Example: Previous Hour Traffic Data)\n",
    "\n",
    "df['PreviousHourVehicles'] = df['Vehicles'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "857cf328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Junction  Vehicles            ID            DateTime  \\\n",
      "DateTime                                                                    \n",
      "2015-01-11 00:00:00       1.0      15.0  2.015110e+10 2015-01-11 00:00:00   \n",
      "2015-01-11 01:00:00       1.0      13.0  2.015110e+10 2015-01-11 01:00:00   \n",
      "2015-01-11 02:00:00       1.0      10.0  2.015110e+10 2015-01-11 02:00:00   \n",
      "2015-01-11 03:00:00       1.0       7.0  2.015110e+10 2015-01-11 03:00:00   \n",
      "2015-01-11 04:00:00       1.0       9.0  2.015110e+10 2015-01-11 04:00:00   \n",
      "\n",
      "                     Hour  DayOfWeek  Month  PreviousHourVehicles  IsWeekend  \n",
      "DateTime                                                                      \n",
      "2015-01-11 00:00:00     0          6      1                   NaN          1  \n",
      "2015-01-11 01:00:00     1          6      1                  15.0          1  \n",
      "2015-01-11 02:00:00     2          6      1                  13.0          1  \n",
      "2015-01-11 03:00:00     3          6      1                  10.0          1  \n",
      "2015-01-11 04:00:00     4          6      1                   7.0          1  \n"
     ]
    }
   ],
   "source": [
    "#Step 3: Binary Indicators\n",
    "\n",
    "df['IsWeekend'] = df['DayOfWeek'].isin([5, 6]).astype(int)  # 1 for weekends, 0 for weekdays\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7cfc066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with Target (Vehicles):\n",
      " Vehicles                1.000000\n",
      "PreviousHourVehicles    0.969982\n",
      "Junction                0.613787\n",
      "ID                      0.227974\n",
      "Hour                    0.219938\n",
      "IsWeekend               0.096628\n",
      "DayOfWeek               0.084059\n",
      "Month                   0.016758\n",
      "Name: Vehicles, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3416\\2192641909.py:4: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  correlation_matrix = df.corr()\n"
     ]
    }
   ],
   "source": [
    "#Evaluating feature importance\n",
    "#Step 1: Correlation Analysis\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "target_correlation = correlation_matrix['Vehicles'].abs().sort_values(ascending=False)\n",
    "print(\"Correlation with Target (Vehicles):\\n\", target_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74c4aa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance from Random Forest:\n",
      " PreviousHourVehicles    0.945431\n",
      "Hour                    0.022886\n",
      "ID                      0.015612\n",
      "Junction                0.005546\n",
      "Month                   0.004960\n",
      "DayOfWeek               0.004868\n",
      "IsWeekend               0.000698\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Feature Importance from Random Forest\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "#Train RandomForestRegressor on the imputed data\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_imputed, y)\n",
    "\n",
    "#Extract feature importance scores\n",
    "\n",
    "feature_importance = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(\"\\nFeature Importance from Random Forest:\\n\", feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d73a83",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Step 3: Extract feature importance scores\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[43mrf\u001b[49m\u001b[38;5;241m.\u001b[39mfeature_importances_, index\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Select the top N most influential features (e.g., top 5 features)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m top_features \u001b[38;5;241m=\u001b[39m feature_importance[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "#Step 3: Extract feature importance scores\n",
    "\n",
    "feature_importance = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Select the top N most influential features (e.g., top 5 features)\n",
    "\n",
    "top_features = feature_importance[:5].index.tolist()\n",
    "\n",
    "# Get the indices of the top features in the original feature matrix X\n",
    "\n",
    "top_feature_indices = [X.columns.get_loc(feature) for feature in top_features]\n",
    "\n",
    "# Subset the feature matrix to include only the selected top features\n",
    "\n",
    "X_selected = X_imputed[:, top_feature_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f309ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
